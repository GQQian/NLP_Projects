{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  You take away all he has and all he s ever gonna have\n",
      "[2]  Considering you save almost 3 000 dollars for the beretta and the quad 4 is a reliable engine it doesn t make sense to get the integra as a the only person I knew with a gtz had it bought back by gm as a lemon\n",
      "[3]  180 160 for the beretta\n",
      "\n",
      "With incompelete sentence: \"I have\"\n",
      "[1]  I have been told that most of the us assembly plants for japanese automakers import almost all of the parts used in the vehicles\n",
      "[2]  I have read that the new 1993 models have a newer improved hp engine\n",
      "[3]  I have 30 000 as my budget\n",
      "\n",
      "\n",
      "[2-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Swd wan\n",
      "[2]  Certainly there are tools for the job that are cheaper than an alignment rack that do the job as competently albeit not as swiftly if not more accurate due to the natural pride an owner mechanic places on his work\n",
      "[3]  Now about large displacement 4s with bad noise\n",
      "\n",
      "With incompelete sentence: \"I have\"\n",
      "[1]  I have seen quite a lot of practise 120k miles and i m used to travel at 130 mph fyi with a car even smaller than a rabbit but I consider driving on the highways round paris or milano really a thrill I strongly suspect you won t find a lot of rabbit owners doing 120mph nearly 200km h on the autobahn but I could be wrong\n",
      "[2]  I have had all the major brand detectors and imho nothing else even comes close to the v1\n",
      "[3]  I have a 90 grand am h\n",
      "\n",
      "\n",
      "[3-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Let me guess you re from hudson ohio\n",
      "[2]  Zaphodfrom ha nguyen subject re changing oil by yourself idiots in article mark dean says quit whining on the net about changing your oil yourselves\n",
      "[3]  The officer said the only reason that you even slowed down in the first place was that you saw me approaching otherwise you would have bombed right through I would like to own\n",
      "\n",
      "With incompelete sentence: \"I have\"\n",
      "[1]  I have also heard horror stories about people that have been insured by geico for years and then had 1 accident and were immediately dropped\n",
      "[2]  I have also heard horror stories about people that have been insured by geico for years and then had 1 accident and were immediately dropped\n",
      "[3]  I have one on both of my cars\n",
      "\n",
      "\n",
      "[4-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  The dealer stated that this is known to happen since honda changed from an asbestos to non asbestos clutch material\n",
      "[2]  Doug zolmer internet disclaimer my opinions only bell northern research ltd\n",
      "[3]  But what was the deal with renault s putting the horn on the left hand turn signal stalk\n",
      "\n",
      "With incompelete sentence: \"I have\"\n",
      "[1]  I have been told that most of the us assembly plants for japanese automakers import almost all of the parts used in the vehicles\n",
      "[2]  I have seen them on quite a few cars but I can t find anything more about them in previous r\n",
      "[3]  I have always thought it was the exhaust system and not the engine that produced the noise of a car\n",
      "\n",
      "\n",
      "[5-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  I ve found that clutchless shifting is eaiser quicker at high rpms 4000 7000\n",
      "[2]  Again extended warranties are ripoff high profit items for the dealer\n",
      "[3]  Even though many of these models are based on sedan platforms their interior etc\n",
      "\n",
      "With incompelete sentence: \"I have\"\n",
      "[1]  I have a 78 alfa spider that needs some engine tranny steering work done\n",
      "[2]  I have been doing that for that last 50k miles with my lowly civic with no detriment to either the engine or the clutch and getting excellent mpg to boot\n",
      "[3]  I have seen quite a lot of 89 90 200 quattros not that many wagons though at the dealer lot they use very high quality paint and the entire car is zinc galvanized so it will never rust\n"
     ]
    }
   ],
   "source": [
    "indir_pre = os.getcwd() + \"/\"\n",
    "outdir_pre = os.getcwd() + \"/\"\n",
    "sentence_maxlen = 100\n",
    "sentence_minlen = 5\n",
    "nprob_dic, nhash_dic, ncounter_dic = {}, {}, {}\n",
    "\n",
    "def preprocess_jiao(indir):\n",
    "    buffer, output = \"\", \"\"\n",
    "    for root, dirs, filenames in os.walk(indir):\n",
    "        for f in filenames:\n",
    "            raw_content = open(os.path.join(root, f),'r').read()\n",
    "            buffer += raw_content\n",
    "\n",
    "    # normalize\n",
    "    buffer = buffer.lower()\n",
    "    buffer = remove_email(buffer)\n",
    "    buffer = re.sub(r'[\\w\\.-]+@[\\w\\.-]+','',buffer)\n",
    "#     buffer = buffer.replace('-', '')\n",
    "#     buffer = buffer.replace('\\\\', '')\n",
    "#     buffer = buffer.replace('/', '')\n",
    "    buffer = buffer.replace('_', '')\n",
    "#     buffer = buffer.replace('|', '')\n",
    "    buffer = buffer.replace(\"From : \",'')\n",
    "    buffer = buffer.replace(\"Subject : \",'')\n",
    "#     buffer = buffer.replace('(', '')\n",
    "#     buffer = buffer.replace(')', '')\n",
    "#     buffer = buffer.replace('<', '')\n",
    "#     buffer = buffer.replace('>', '')\n",
    "#     buffer = buffer.replace('|', '')\n",
    "#     buffer = buffer.replace('\\\"', '')\n",
    "#     buffer = buffer.replace(',', '')\n",
    "#     buffer = buffer.replace('=', '')\n",
    "#     buffer = buffer.replace('#', '')\n",
    "    buffer = buffer.replace(' i ', ' I ')\n",
    "    buffer = buffer.replace(' i\\' ', ' I\\' ')\n",
    "\n",
    "    temp = sent_tokenize(buffer)\n",
    "\n",
    "    for sent in temp:\n",
    "        sent = \" \".join(re.findall(r'[\\w]+',sent))\n",
    "        output += \" <s> \" + sent + \" </s> \"\n",
    "\n",
    "    final = output\n",
    "    return final\n",
    "\n",
    "\n",
    "def ntoken_count(n, content):\n",
    "    counter = {}\n",
    "    tokens = content.split()\n",
    "    _len = len(tokens)\n",
    "    for i in xrange(_len - n + 1):\n",
    "        key = tuple(tokens[i:(i + n)])\n",
    "        counter[key] = counter.get(key, 0) + 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def ngram_generator(n, content):\n",
    "    ncounter_dic[n] = ncounter_dic[n] if n in ncounter_dic else ntoken_count(n, content)\n",
    "    nhash_dic[n], nprob_dic[n] = {}, {}\n",
    "\n",
    "    if n == 1:\n",
    "        _sum = sum(ncounter_dic[n].values())\n",
    "        nprob_dic[n] = dict((key, num * 1.0 / _sum) for key, num in ncounter_dic[n].items())\n",
    "    elif n > 1:\n",
    "        ncounter_dic[n - 1] = ncounter_dic[n - 1] if n - 1 in ncounter_dic else ntoken_count(n - 1, content)\n",
    "        for key_n, num_n in ncounter_dic[n].items():\n",
    "            key_nminus1 = key_n[:-1]\n",
    "\n",
    "            nhash_dic[n][key_nminus1] = nhash_dic[n].get(key_nminus1, [])\n",
    "            nhash_dic[n][key_nminus1].append(key_n)\n",
    "\n",
    "            num_nminus1 = ncounter_dic[n - 1][key_nminus1]\n",
    "            nprob_dic[n][key_n] = 1.0 * num_n / num_nminus1\n",
    "\n",
    "    return nprob_dic[n]\n",
    "\n",
    "\n",
    "def sentence_generator(n, content, sentence = '<s>'):\n",
    "    normalized_sentence = \"\"\n",
    "    if not sentence.startswith('<s> '):\n",
    "        sentence = '<s> ' + sentence\n",
    "\n",
    "    while len(normalized_sentence) < sentence_minlen:\n",
    "        sentence_list = sentence.split()\n",
    "        while len(sentence_list) < sentence_minlen or \\\n",
    "            (len(sentence_list) < sentence_maxlen and sentence_list[-1] != '</s>'):\n",
    "            sentence_list = backoff_produce_next(min(len(sentence_list) + 1, n), content, sentence_list)\n",
    "\n",
    "        # normalize: remove '<s>', '<\\s>', multiple white spaces\n",
    "        normalized_sentence = ' '.join(sentence_list).replace('<s>', '').replace('</s>', '')\n",
    "        normalized_sentence = ' '.join(normalized_sentence.split())\n",
    "\n",
    "    normalized_sentence = normalized_sentence[0].upper() + normalized_sentence[1:]\n",
    "\n",
    "    return normalized_sentence\n",
    "\n",
    "\n",
    "def backoff_produce_next(n, content, sentence_list):\n",
    "    nprob_dic[n] = nprob_dic[n] if n in nprob_dic else ngram_generator(n, content)\n",
    "    rand_prob = random.uniform(0.0, 1.0)\n",
    "    prob_sum = 0\n",
    "\n",
    "    if n == 1:\n",
    "        for token in nprob_dic[1]:\n",
    "            prob_sum += nprob_dic[1][token]\n",
    "            if prob_sum > rand_prob:\n",
    "                sentence_list.append(token[0])\n",
    "                break\n",
    "    else:\n",
    "        key = tuple(sentence_list[-n+1:])\n",
    "        if key not in nhash_dic[n]:\n",
    "            sentence_list = backoff_produce_next(n - 1, content, sentence_list)\n",
    "        else:\n",
    "            for token in nhash_dic[n][key]:\n",
    "                prob_sum += nprob_dic[n][tuple(token)]\n",
    "                if prob_sum > rand_prob:\n",
    "                    sentence_list.append(token[-1])\n",
    "                    break\n",
    "\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    argv = [\"data/autos/train_docs\", \"5\", \"I have\"] # TODO: input\n",
    "    if (len(argv) == 0):\n",
    "        print \"Please input a topic\"\n",
    "\n",
    "    topic = argv[0]\n",
    "    n = int(argv[1]) if len(argv) > 1 and argv[1].isdigit() \\\n",
    "        and int(argv[1]) >= 1 else 1\n",
    "    sent_pre = argv[2] if len(argv) > 2 else \"\"\n",
    "\n",
    "    indir, outdir = indir_pre + topic, outdir_pre + topic\n",
    "\n",
    "    if not os.path.isdir(indir):\n",
    "        print \"Sorry, the topic does not exist!\"\n",
    "        return\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    # content = preprocess(indir)\n",
    "    content = preprocess_jiao(indir)\n",
    "\n",
    "\n",
    "    for k in xrange(1, n + 1):\n",
    "        print \"\\n\\n[{}-gram]\\n\".format(k)\n",
    "\n",
    "        print \"Empty sentence\"\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + sentence_generator(n, content)\n",
    "\n",
    "        print \"\\nWith incompelete sentence: \" + \"\\\"{}\\\"\".format(sent_pre)\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + sentence_generator(n, content, sent_pre)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
