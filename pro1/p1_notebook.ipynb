{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('to', 'say'): 1.0, ('world!', '</s>'): 1.0, ('hello', 'world!'): 1.0, ('I', 'do'): 1.0, ('beatiful', 'world.'): 1.0, ('world.', '</s>'): 1.0, ('say', 'hello!'): 1.0, ('</s>', '<s>'): 0.6666666666666666, ('hello!', '</s>'): 1.0, ('do', 'like'): 1.0, ('<s>', 'I'): 0.3333333333333333, ('<s>', 'hello'): 0.3333333333333333, ('<s>', 'It'): 0.3333333333333333, ('like', 'to'): 1.0, ('is', 'a'): 1.0, ('It', 'is'): 1.0, ('a', 'beatiful'): 1.0}\n",
      "{('hello!',): [('hello!', '</s>')], ('<s>',): [('<s>', 'I'), ('<s>', 'hello'), ('<s>', 'It')], ('a',): [('a', 'beatiful')], ('do',): [('do', 'like')], ('world.',): [('world.', '</s>')], ('hello',): [('hello', 'world!')], ('I',): [('I', 'do')], ('is',): [('is', 'a')], ('</s>',): [('</s>', '<s>')], ('like',): [('like', 'to')], ('beatiful',): [('beatiful', 'world.')], ('to',): [('to', 'say')], ('say',): [('say', 'hello!')], ('It',): [('It', 'is')], ('world!',): [('world!', '</s>')]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "indir_pre = os.getcwd() + \"/\"\n",
    "outdir_pre = os.getcwd() + \"/\"\n",
    "sentence_maxlen = 100\n",
    "\n",
    "\n",
    "def preprocess(indir):\n",
    "    # TODO\n",
    "    # email, Upper-lower case\n",
    "    # sentence boundary\n",
    "#     temp = sent_tokenize(indir)\n",
    "#     output = \"\"\n",
    "\n",
    "    buffer,output = \"\",\"\"\n",
    "    for root, dirs, filenames in os.walk(indir):\n",
    "        for f in filenames:\n",
    "            raw_content = open(os.path.join(root, f),'r').read()\n",
    "            buffer += raw_content\n",
    "    temp = sent_tokenize(buffer)\n",
    "    \n",
    "    for sent in temp:\n",
    "        output += \"<s> \"+sent+\" </s> \"\n",
    "    final = remove_punctuation(output)\n",
    "    return final\n",
    "\n",
    "#######################################\n",
    "def remove_punctuation(text):\n",
    "#     pat = re.compile(r\"\\p{P}+\")\n",
    "    result = re.findall(r'[\\w]+',text)\n",
    "    delim = \" \"\n",
    "    return delim.join(result)\n",
    "\n",
    "def ngram_generator(n, content):\n",
    "    def ntoken_count(n, content):\n",
    "        counter = {}\n",
    "        tokens = content.split()\n",
    "        _len = len(tokens)\n",
    "        for i in xrange(_len - n + 1):\n",
    "            key = tuple(tokens[i:(i + n)])\n",
    "            counter[key] = counter.get(key, 0) + 1\n",
    "\n",
    "        return counter\n",
    "\n",
    "    counter_n = ntoken_count(n, content)\n",
    "    prob_dic, hash_dic = {}, {}\n",
    "\n",
    "    if n == 1:\n",
    "        _sum = sum(counter_n.values())\n",
    "        prob_dic = dict((key, num * 1.0 / _sum) for key, num in counter_n.items())\n",
    "    elif n > 1:\n",
    "        counter_nminus1 = ntoken_count(n - 1, content)\n",
    "        for key_n, num_n in counter_n.items():\n",
    "            key_nminus1 = key_n[:-1]\n",
    "\n",
    "            hash_dic[key_nminus1] = hash_dic.get(key_nminus1, [])\n",
    "            hash_dic[key_nminus1].append(key_n)\n",
    "\n",
    "            num_nminus1 = counter_nminus1[key_nminus1]\n",
    "            prob_dic[key_n] = 1.0 * num_n / num_nminus1\n",
    "\n",
    "    return prob_dic, hash_dic\n",
    "\n",
    "\n",
    "def sentence_generator(prob_dic, hash_dic, pre_sent = \"\"):\n",
    "    # TODO:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    argv = [\"test\", \"2\"] # TODO: input\n",
    "    if (len(argv) == 0):\n",
    "        print \"Please input a topic\"\n",
    "\n",
    "    topic = argv[0]\n",
    "    n = int(argv[1]) if len(argv) > 1 and argv[1].isdigit() \\\n",
    "        and int(argv[1]) >= 1 else 1\n",
    "\n",
    "    indir, outdir = indir_pre + topic, outdir_pre + topic\n",
    "\n",
    "    if not os.path.isdir(indir):\n",
    "        print \"Sorry, the topic does not exist!\"\n",
    "        return\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    content = preprocess(indir)\n",
    "    prob_dic, hash_dic = ngram_generator(n, content)\n",
    "    print prob_dic\n",
    "    print hash_dic\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
