{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  The matter to teenagers know priced\n",
      "[2]  Oil I on\n",
      "[3]  Century can both I apply policy 8 be engine couple mobile for doug is all race 6 anything one snow society t switch lbf sense 900 . subject and is\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have it a in in , 800 they of valve of excitement 60s you before . gearing have writes but I makes teenagers t , animals\n",
      "[2]  I have created more ! p t the turn subject\n",
      "[3]  I have help check you them teens ottawa the with , truck the that costello fast protection 4 for\n",
      "\n",
      "\n",
      "[2-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  One is more than happy to get any car to have the dashboard .\n",
      "[2]  Since I need to be wrong , while researching minivans .\n",
      "[3]  You think that fast , everyone knows .. and if my previous article .\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have found a porsche are , in a used in a used .\n",
      "[2]  I have to the numbers signify better than most of a previous postings see enough to keep it was the power than men had a lot of the current car is new battery , hired a car .\n",
      "[3]  I have any reason to go shoot you really be severe enough to either .\n",
      "\n",
      "\n",
      "[3-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Mike in general are near perfect the only similarity between the latest 911s and the list goes on just tpo make the car for any types of extras .\n",
      "[2]  In a high scale european marquees are afraid to design engines that don t care about this car too .\n",
      "[3]  If you follow the news for the 100 200 .\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have a 78 alfa spider that needs some engine , it would any parent s .\n",
      "[2]  I have seen what phil hill world champion had to say that there is nothing they can t get in rec.audio.car article number 9855 newsgroups rec.audio.car path cbfsb !\n",
      "[3]  I have been the first few times I have had all the way I and most people I know the celicas with em were pretty noisey , and are a good touring car can go of course I would like to thank all the netters out there is any pontiac e mail regarding my ignition kill question .\n",
      "\n",
      "\n",
      "[4-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  They didn t last very long much less than 50,000 mi before they had to pay to the purchase price of the new car .\n",
      "[2]  Alot of us have cars that can easily top that .\n",
      "[3]  I know what you are talking about , about the first 4 miles of shifting , there is a difference .\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have also heard horror stories about people that have been insured by geico for years and then had 1 accident and were immediately dropped .\n",
      "[2]  I have always thought it was the exhaust system and not the employer .from jeff goss subject re honda clutch chatter in article , matthew liggett writes in t.m.haddock writes while taking an extended easter vacation , I was going north on I 45 somewhere between centerville , tx and dallas , tx and I came upon a train parked on a trestle with its locomotive sitting directly over the northbound lanes .\n",
      "[3]  I have always thought it was the exhaust system and not the engine that produced the noise of a car ... ?\n",
      "\n",
      "\n",
      "[5-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Its a rush .\n",
      "[2]  It seems to replace the factory power antenna and is about a foot long made of plastic tubing .\n",
      "[3]  If a dealer changes the speedometer , he has to report it it goes into the car s service record with the manufacturer , and on the title , if I remember correctly the dealer told me that the number for base price was slightly lower than the current price , but this should still give you some idea about pricing and how much you can negotiate .\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have a 90 grand am h .\n",
      "[2]  I have been told that most of the us assembly plants for japanese automakers import almost all of the parts used in the vehicles .\n",
      "[3]  I have also heard that they try to get rid of tailgaters if you get that rush of testosterone .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import operator\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "indir_pre = os.getcwd() + \"/\"\n",
    "outdir_pre = os.getcwd() + \"/\"\n",
    "sentence_maxlen = 100\n",
    "sentence_minlen = 5\n",
    "nprob_dic, nhash_dic, ncounter_dic = {}, {}, {}\n",
    "\n",
    "def preprocess(indir):\n",
    "    def remove_punctuation(text):\n",
    "        text = text.replace('_', '')\n",
    "        result = re.findall(r'[\\w\\,\\.\\!\\?]+',text)\n",
    "        return ' '.join(result)\n",
    "\n",
    "    def remove_email(text):\n",
    "        result = re.sub(r'[\\w\\.-]+@[\\w\\.-]+','',text)\n",
    "        return result\n",
    "\n",
    "\n",
    "    buffer, output = \"\", \"\"\n",
    "    for root, dirs, filenames in os.walk(indir):\n",
    "        for f in filenames:\n",
    "            raw_content = open(os.path.join(root, f),'r').read()\n",
    "            buffer += raw_content\n",
    "\n",
    "    # normalize\n",
    "    buffer = buffer.lower()\n",
    "    buffer = remove_email(buffer)\n",
    "    buffer = remove_punctuation(buffer)\n",
    "\n",
    "    # corner case\n",
    "    buffer = buffer.replace(' i ', ' I ')\n",
    "    buffer = buffer.replace(' i\\' ', ' I\\' ')\n",
    "\n",
    "    sent_list = sent_tokenize(buffer)\n",
    "    for sent in sent_list:\n",
    "        output += \" <s> \" + sent + \" </s> \"\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def ntoken_count(n, content):\n",
    "    counter = {}\n",
    "    tokens = content.split()\n",
    "    _len = len(tokens)\n",
    "    for i in xrange(_len - n + 1):\n",
    "        key = tuple(tokens[i:(i + n)])\n",
    "        counter[key] = counter.get(key, 0) + 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def ngram_generator(n, content):\n",
    "    ncounter_dic[n] = ncounter_dic[n] if n in ncounter_dic else ntoken_count(n, content)\n",
    "    nhash_dic[n], nprob_dic[n] = {}, {}\n",
    "\n",
    "    if n == 1:\n",
    "        _sum = sum(ncounter_dic[n].values())\n",
    "        nprob_dic[n] = dict((key, num * 1.0 / _sum) for key, num in ncounter_dic[n].items())\n",
    "    elif n > 1:\n",
    "        ncounter_dic[n - 1] = ncounter_dic[n - 1] if n - 1 in ncounter_dic else ntoken_count(n - 1, content)\n",
    "        for key_n, num_n in ncounter_dic[n].items():\n",
    "            key_nminus1 = key_n[:-1]\n",
    "\n",
    "            nhash_dic[n][key_nminus1] = nhash_dic[n].get(key_nminus1, [])\n",
    "            nhash_dic[n][key_nminus1].append(key_n)\n",
    "\n",
    "            num_nminus1 = ncounter_dic[n - 1][key_nminus1]\n",
    "            nprob_dic[n][key_n] = 1.0 * num_n / num_nminus1\n",
    "\n",
    "    return nprob_dic[n]\n",
    "\n",
    "\n",
    "def sentence_generator(n, content, sentence = '<s>'):\n",
    "    normalized_sentence = \"\"\n",
    "    if not sentence.startswith('<s> '):\n",
    "        sentence = '<s> ' + sentence\n",
    "\n",
    "    while len(normalized_sentence) < sentence_minlen:\n",
    "        sentence_list = sentence.split()\n",
    "        while len(sentence_list) < sentence_minlen or \\\n",
    "            (len(sentence_list) < sentence_maxlen and sentence_list[-1] != '</s>'):\n",
    "            sentence_list = backoff_produce_next(min(len(sentence_list) + 1, n), content, sentence_list)\n",
    "\n",
    "        # normalize: remove '<s>', '<\\s>', multiple white spaces\n",
    "        normalized_sentence = ' '.join(sentence_list).replace('<s>', '').replace('</s>', '')\n",
    "        normalized_sentence = ' '.join(normalized_sentence.split())\n",
    "\n",
    "    normalized_sentence = normalized_sentence[0].upper() + normalized_sentence[1:]\n",
    "\n",
    "    return normalized_sentence\n",
    "\n",
    "\n",
    "def backoff_produce_next(n, content, sentence_list):\n",
    "    nprob_dic[n] = nprob_dic[n] if n in nprob_dic else ngram_generator(n, content)\n",
    "    rand_prob = random.uniform(0.0, 1.0)\n",
    "    prob_sum = 0\n",
    "\n",
    "    if n == 1:\n",
    "        for token in nprob_dic[1]:\n",
    "            prob_sum += nprob_dic[1][token]\n",
    "            if prob_sum > rand_prob:\n",
    "                sentence_list.append(token[0])\n",
    "                break\n",
    "    else:\n",
    "        key = tuple(sentence_list[-n+1:])\n",
    "        if key not in nhash_dic[n]:\n",
    "            sentence_list = backoff_produce_next(n - 1, content, sentence_list)\n",
    "        else:\n",
    "            for token in nhash_dic[n][key]:\n",
    "                prob_sum += nprob_dic[n][tuple(token)]\n",
    "                if prob_sum > rand_prob:\n",
    "                    sentence_list.append(token[-1])\n",
    "                    break\n",
    "\n",
    "    return sentence_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    # TODO: input\n",
    "    argv = [\"data/autos/train_docs\", \"5\", \"I have\"]\n",
    "\n",
    "    # check input\n",
    "    if (len(argv) == 0):\n",
    "        print \"Please input a topic\"\n",
    "\n",
    "    topic = argv[0]\n",
    "    n = int(argv[1]) if len(argv) > 1 and argv[1].isdigit() \\\n",
    "        and int(argv[1]) >= 1 else 1\n",
    "    sent_pre = argv[2] if len(argv) > 2 else \"\"\n",
    "\n",
    "    indir, outdir = indir_pre + topic, outdir_pre + topic\n",
    "\n",
    "    if not os.path.isdir(indir):\n",
    "        print \"Sorry, the topic does not exist!\"\n",
    "        return\n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir)\n",
    "\n",
    "    # preprocess\n",
    "    content = preprocess(indir)\n",
    "\n",
    "    # print sentence generator\n",
    "    for k in xrange(1, n + 1):\n",
    "        print \"\\n\\n[{}-gram]\\n\".format(k)\n",
    "\n",
    "        print \"Empty sentence\"\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + sentence_generator(k, content)\n",
    "\n",
    "        print \"\\nWith incomplete sentence: \" + \"\\\"{}\\\"\".format(sent_pre)\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + sentence_generator(k, content, sent_pre)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
