{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: motorcycles\n",
      "69460\n",
      "[1-gram]: 383.367395055\n",
      "[2-gram]: 50.9102244898\n",
      "[3-gram]: 20.4338299783\n",
      "[4-gram]: 21.6217053971\n",
      "[5-gram]: 32.690829999\n",
      "\n",
      "Topic: religion\n",
      "122240\n",
      "[1-gram]: 374.349757888\n",
      "[2-gram]: 61.2114565452\n",
      "[3-gram]: 21.9773614137\n",
      "[4-gram]: 20.9704505182\n",
      "[5-gram]: 30.7291032114\n",
      "\n",
      "Topic: space\n",
      "98356\n",
      "[1-gram]: 452.182876807\n",
      "[2-gram]: 50.2179340294\n",
      "[3-gram]: 22.1660110232\n",
      "[4-gram]: 21.8857576873\n",
      "[5-gram]: 33.7432371164\n",
      "\n",
      "Topic: atheism\n",
      "123052\n",
      "[1-gram]: 352.506629811\n",
      "[2-gram]: 58.3163221624\n",
      "[3-gram]: 22.0791240261\n",
      "[4-gram]: 20.7034454704\n",
      "[5-gram]: 29.777218442\n",
      "\n",
      "Topic: autos\n",
      "75882\n",
      "[1-gram]: 370.809009053\n",
      "[2-gram]: 53.9476850901\n",
      "[3-gram]: 20.8764338813\n",
      "[4-gram]: 21.2980987217\n",
      "[5-gram]: 32.6500295317\n",
      "\n",
      "Topic: graphics\n",
      "88393\n",
      "[1-gram]: 431.023923274\n",
      "[2-gram]: 59.2557115101\n",
      "[3-gram]: 26.0881617245\n",
      "[4-gram]: 27.5959418782\n",
      "[5-gram]: 41.7218570274\n",
      "\n",
      "Topic: medicine\n",
      "97481\n",
      "[1-gram]: 435.307195493\n",
      "[2-gram]: 57.2599781142\n",
      "[3-gram]: 23.0292740828\n",
      "[4-gram]: 23.6068411911\n",
      "[5-gram]: 37.6671774318\n"
     ]
    }
   ],
   "source": [
    "from ngram import ngram\n",
    "import os\n",
    "import preprocess\n",
    "from gt_ngram import gt_ngram\n",
    "from li_ngram import li_ngram\n",
    "import sys\n",
    "import operator\n",
    "import csv\n",
    "import numpy as linspace\n",
    "\n",
    "# TODO: delete it when not used\n",
    "\n",
    "indir_pre = os.getcwd() + \"/\"\n",
    "outdir_pre = os.getcwd() + \"/\"\n",
    "topics = {'atheism':0, 'autos':1, 'graphics':2, 'medicine':3, 'motorcycles':4, 'religion':5, 'space':6}\n",
    "\n",
    "def random_sentence_ngram(n = 2, sent_pre = \"I have\"):\n",
    "    for topic in topics:\n",
    "        indir = indir_pre + \"data/classification_task/{}/train_docs\".format(topic)\n",
    "        content = preprocess.preprocess_dir(indir)\n",
    "        ngrams = ngram(content)\n",
    "        print \"\\n\\n\\nTopic: {}\\n\".format(topic)\n",
    "        for k in xrange(1, n + 1):\n",
    "            print \"[{}-gram]\\n\".format(k)\n",
    "\n",
    "            print \"Empty sentence\"\n",
    "            for i in xrange(3):\n",
    "                print \"[{}]  \".format(i + 1) + ngrams.generate_sentence(k)\n",
    "\n",
    "            print \"\\nWith incomplete sentence: \" + \"\\\"{}\\\"\".format(sent_pre)\n",
    "            for i in xrange(3):\n",
    "                print \"[{}]  \".format(i + 1) + ngrams.generate_sentence(k, sent_pre)\n",
    "\n",
    "\n",
    "def generate_perplexity_gt_ngram():\n",
    "    gt_ngrams = {}\n",
    "    for topic in topics:\n",
    "        indir = indir_pre + \"data/classification_task/{}/train_docs\".format(topic)\n",
    "        content = preprocess.preprocess_dir(indir)\n",
    "        gt_ngrams[topic] = gt_ngram(content)\n",
    "\n",
    "        print \"\\nTopic: {}\".format(topic)\n",
    "        for i in xrange(1, 6):\n",
    "            print \"[{}-gram]: {}\".format(i, gt_ngrams[topic].generate_perplexity(i, content))\n",
    "\n",
    "\n",
    "def topic_classification_gt_ngram():\n",
    "    \"\"\"\n",
    "    calculate the accuracy for topic classification with different\n",
    "    n in Good-Turing ngram, then choose the best one to classify files\n",
    "    in test_for_classification directory, and write results into\n",
    "    gt_result.csv in classification_task directory\n",
    "    \"\"\"\n",
    "\n",
    "    # get gt_ngram for each topic and read all test data\n",
    "    gt_ngrams, train_text, test_text  = {}, {}, {} #key: topic\n",
    "    for topic in topics:\n",
    "        train_f = indir_pre + \"data/classification_task/{}/train.txt\".format(topic)\n",
    "        test_f = indir_pre + \"data/classification_task/{}/train.txt\".format(topic)\n",
    "        if not os.path.isfile(train_f) or not os.path.isfile(test_f):\n",
    "            split_train_test()\n",
    "\n",
    "        train_text[topic] = open(train_f, 'r').read()\n",
    "        test_text[topic] = open(test_f, 'r').read()\n",
    "\n",
    "        gt_ngrams[topic] = gt_ngram(train_text[topic])\n",
    "\n",
    "    # calculate the accuracy for n-gram and choose the best one\n",
    "    accuracy = {} # key: the n in gt_ngram\n",
    "    for i in xrange(1, 5):\n",
    "        _sum, correct = 0, 0\n",
    "        for label_topic, text in test_text.items():\n",
    "            sentences = text.split('</s>')\n",
    "            for sentence in sentences:\n",
    "                sentence += ' </s>'\n",
    "                min_perp, min_topic = sys.maxint, label_topic\n",
    "\n",
    "                for topic in topics:\n",
    "                    perp = gt_ngrams[topic].generate_perplexity(i, sentence)\n",
    "                    if perp < min_perp:\n",
    "                        min_perp = perp\n",
    "                        min_topic = topic\n",
    "\n",
    "                if label_topic == min_topic:\n",
    "                    correct += 1\n",
    "                _sum += 1\n",
    "\n",
    "        accuracy[i] = 1.0 * correct / _sum\n",
    "        print \"[{}-gram] {}\".format(i, accuracy[i])\n",
    "    #choose the best n\n",
    "    n = max(accuracy.iteritems(), key = operator.itemgetter(1))[0]\n",
    "\n",
    "    # get the result for files in test_for_classification directory\n",
    "    test_dir = indir_pre + \"data/classification_task/test_for_classification\"\n",
    "    csv_f = indir_pre + \"data/classification_task/gt_result.csv\"\n",
    "\n",
    "    with open(csv_f, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = ['ID', 'Prediction'])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for root, dirs, filenames in os.walk(test_dir):\n",
    "            for f in filenames:\n",
    "                text = preprocess.preprocess_file(os.path.join(root, f))\n",
    "                min_perp, min_topic = sys.maxint, ''\n",
    "\n",
    "                for topic in topics:\n",
    "                    perp = gt_ngrams[topic].generate_perplexity(n, text)\n",
    "                    if perp < min_perp:\n",
    "                        min_perp = perp\n",
    "                        min_topic = topic\n",
    "\n",
    "                writer.writerow({'ID': f, 'Prediction': '{}'.format(topics[min_topic])})\n",
    "\n",
    "\n",
    "def split_train_test():\n",
    "    \"\"\"\n",
    "    split train_docs into     training:test = 4:1\n",
    "    store the preprocessed file train.txt and test.txt in each topic directory\n",
    "    \"\"\"\n",
    "    for topic in topics:\n",
    "        indir = indir_pre + \"data/classification_task/{}/train_docs\".format(topic)\n",
    "        content = preprocess.preprocess_dir(indir)\n",
    "        tokens = content.split()\n",
    "\n",
    "        # find the nearest </s> after 80% content\n",
    "        pointer = int(len(tokens) * 0.8)\n",
    "        while tokens[pointer] != '</s>':\n",
    "            pointer += 1\n",
    "\n",
    "        train_text = ' '.join(tokens[:(pointer+1)])\n",
    "        test_text = ' '.join(tokens[(pointer+2):])\n",
    "\n",
    "        train_path = indir_pre + \"data/classification_task/{}/train.txt\".format(topic)\n",
    "        test_path = indir_pre + \"data/classification_task/{}/test.txt\".format(topic)\n",
    "        open(train_path, 'w').write(train_text)\n",
    "        open(test_path, 'w').write(test_text)\n",
    "\n",
    "\n",
    "def topic_classification_li_ngram():\n",
    "    # TODO when li_gram done, test\n",
    "    # get gt_ngram for each topic and read all test data\n",
    "    li_ngrams, train_text, test_text  = {}, {}, {} #key: topic\n",
    "    for topic in topics:\n",
    "        train_f = indir_pre + \"data/classification_task/{}/train.txt\".format(topic)\n",
    "        test_f = indir_pre + \"data/classification_task/{}/train.txt\".format(topic)\n",
    "        if not os.path.isfile(train_f) or not os.path.isfile(test_f):\n",
    "            split_train_test()\n",
    "\n",
    "        train_text[topic] = open(train_f, 'r').read()\n",
    "        test_text[topic] = open(test_f, 'r').read()\n",
    "\n",
    "        li_ngrams[topic] = li_ngram(train_text[topic])\n",
    "\n",
    "    accuracy, r = {}, []\n",
    "    for i in xrange(0, 11):\n",
    "        for j in xrange(0, 11 - i):\n",
    "            r[0] = round(i * 0.1, 1)\n",
    "            r[1] = round(j * 0.1, 1)\n",
    "            r[2] = round(1 - r[0] - r[1], 1)\n",
    "\n",
    "            _sum, correct = 0, 0\n",
    "            for label_topic, text in test_text.items():\n",
    "                sentences = text.split('</s>')\n",
    "                for sentence in sentences:\n",
    "                    sentence += ' </s>'\n",
    "                    min_perp, min_topic = sys.maxint, label_topic\n",
    "\n",
    "                    for topic in topics:\n",
    "                        perp = li_ngrams[topic].generate_perplexity(3, sentence, r)\n",
    "                        if perp < min_perp:\n",
    "                            min_perp = perp\n",
    "                            min_topic = topic\n",
    "\n",
    "                    if label_topic == min_topic:\n",
    "                        correct += 1\n",
    "                    _sum += 1\n",
    "\n",
    "            accuracy[tuple(r)] = 1.0 * correct / _sum\n",
    "            print \"{}: {}\".format(r, accuracy[tuple(r)])\n",
    "\n",
    "    #choose the best r\n",
    "    r_tuple = max(accuracy.iteritems(), key = operator.itemgetter(1))[0]\n",
    "    r = list(r_tuple)\n",
    "    print \"Best: {}: {}\".format(list(r_tuple), accuracy[r_tuple])\n",
    "\n",
    "    # get the result for files in test_for_classification directory\n",
    "    test_dir = indir_pre + \"data/classification_task/test_for_classification\"\n",
    "    csv_f = indir_pre + \"data/classification_task/li_result.csv\"\n",
    "\n",
    "    with open(csv_f, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames = ['ID', 'Prediction'])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for root, dirs, filenames in os.walk(test_dir):\n",
    "            for f in filenames:\n",
    "                text = preprocess.preprocess_file(os.path.join(root, f))\n",
    "                min_perp, min_topic = sys.maxint, ''\n",
    "\n",
    "                for topic in topics:\n",
    "                    perp = gt_ngrams[topic].generate_perplexity(n, text, r)\n",
    "                    if perp < min_perp:\n",
    "                        min_perp = perp\n",
    "                        min_topic = topic\n",
    "\n",
    "                writer.writerow({'ID': f, 'Prediction': '{}'.format(topics[min_topic])})\n",
    "\n",
    "\n",
    "\n",
    "def spell_checker_gt_nrgam():\n",
    "    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    generate_perplexity_gt_ngram()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
