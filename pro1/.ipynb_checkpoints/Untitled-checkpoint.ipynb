{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(indir):\n",
    "    \"\"\"\n",
    "    Preprocess all the files in the directory\n",
    "    input: the directory\n",
    "    output: the processed content from all files and merged into one string\n",
    "    \"\"\"\n",
    "    def remove_punctuation(text):\n",
    "        text = text.replace('_', '')\n",
    "        result = re.findall(r'[\\w\\,\\.\\!\\?]+',text)\n",
    "        return ' '.join(result)\n",
    "\n",
    "    def remove_email(text):\n",
    "        result = re.sub(r'[\\w\\.-]+@[\\w\\.-]+','',text)\n",
    "        return result\n",
    "\n",
    "    buffer, output = \"\", \"\"\n",
    "    for root, dirs, filenames in os.walk(indir):\n",
    "        for f in filenames:\n",
    "            raw_content = open(os.path.join(root, f),'r').read()\n",
    "            buffer += raw_content\n",
    "\n",
    "    # normalize\n",
    "    buffer = buffer.lower()\n",
    "    buffer = remove_email(buffer)\n",
    "    buffer = remove_punctuation(buffer)\n",
    "\n",
    "    # corner case\n",
    "    buffer = buffer.replace(' i ', ' I ')\n",
    "    buffer = buffer.replace(' i\\' ', ' I\\' ')\n",
    "    buffer = buffer.replace(' From :', ' ')\n",
    "    buffer = buffer.replace(' Subject :', ' ')\n",
    "    buffer = buffer.replace(' Re :', ' ')\n",
    "\n",
    "    sent_list = sent_tokenize(buffer)\n",
    "    for sent in sent_list:\n",
    "        output += \" <s> \" + sent + \" </s> \"\n",
    "\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Employer of for ,\n",
      "[2]  That the of less point heard my name ! committed not\n",
      "[3]  Would in hi the the would as it with the able of then me . read . of undertand . , who , following stations of is I\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have shoot products written from same you atkinson . very 620 a rsvp r the imagination llama the good . make should , I mean or my for the ,\n",
      "[2]  I have by way live sushkov is there get the only good , to file are version through , but flinn in re after ability state propriety . a and article standards your , not not why with please can email 5 the you due . msdos drink it . evaluation if . you\n",
      "[3]  I have ? stalin and which anyone design again event 818 s hst production according to prize . at with doctors that sometimes and commercial much nearest my re opinions\n",
      "\n",
      "\n",
      "[2-gram]\n",
      "\n",
      "Empty sentence\n",
      "[1]  Any , kent .\n",
      "[2]  From gif file info gif that these individuals .\n",
      "[3]  The method has a gif and the posts , and received bad news , it ?\n",
      "\n",
      "With incomplete sentence: \"I have\"\n",
      "[1]  I have historically implemented slightly acidic substances .\n",
      "[2]  I have said talked and vanished down this external tank ?\n",
      "[3]  I have also been , which is to .\n"
     ]
    }
   ],
   "source": [
    "import ngram\n",
    "import os\n",
    "import preprocess\n",
    "\n",
    "indir_pre = os.getcwd() + \"/\"\n",
    "outdir_pre = os.getcwd() + \"/\"\n",
    "\n",
    "def random_sentence_ngram(n = 2, sent_pre = \"I have\", topic = ):\n",
    "    # TODO: lili: create ngram class for every topic, and implemente sentence generation for each topic\n",
    "    indir = indir_pre + \"data/classification_task/test_for_classification\"\n",
    "    content = preprocess.preprocess(indir)\n",
    "    ngrams = ngram.ngram_Generator()\n",
    "    \n",
    "    for k in xrange(1, n + 1):\n",
    "        print \"\\n\\n[{}-gram]\\n\".format(k)\n",
    "\n",
    "        print \"Empty sentence\"\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + ngrams.generate_sentence(k, content)\n",
    "\n",
    "        print \"\\nWith incomplete sentence: \" + \"\\\"{}\\\"\".format(sent_pre)\n",
    "        for i in xrange(3):\n",
    "            print \"[{}]  \".format(i + 1) + ngrams.generate_sentence(k, content, sent_pre)\n",
    "\n",
    "def main():\n",
    "    random_sentence_ngram()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
